# INFO833 | Extract - Transform - Load


Un ETL est un logiciel permettant d'int√©grer des grands volumes de donn√©es de diff√©rents types, en provenance de diff√©rentes sources. Il extrait les donn√©es brutes, les restructure et enfin les charge dans un Data Warehouse. Ces op√©rations sont r√©alis√©es en temps r√©el et permettent d'enrichir les donn√©es et de prendre en charge des milliards de transactions.

La finalit√© du TP est d'impl√©menter un syst√®me de gestion d'ETL √† large √©chelle en fixant un certain nombre de t√¢ches √† traiter. Nous avons choisi d'impl√©menter 3 t√¢ches dans le projet.

## üí≠ Un ETL avec Redis
### 1Ô∏è‚É£ ETL de base
On construit un fichier tasks.py qui contient la d√©finition de toutes les t√¢ches. Connaissant les param√®tres et le nom d'une t√¢che, on peut ainsi l'ex√©cuter dans n'importe quel cluster. On suppose ensuite qu'on va ex√©cuter une s√©quence de t√¢ches : T1, suivi de T2, puis de T3, etc. Les param√®tres d'entr√©e sont g√©n√©r√©s dans une file qu'on appelle task_queue, que le programme lit pour pouvoir instancier la prochaine t√¢che √† faire. La file se vide quand le traitement est termin√©.

Cette conception est impl√©ment√©e dans le fichier **main_ETL.py**. 

### 2Ô∏è‚É£ Un ETL avec un cache Redis
On suppose que task_queue est mise en place sous Redis en tant que liste et on impl√©mente le m√™me syst√®me ETL qu'en premi√®re partie.
Sachant que nous avions d√©j√† Redis sur nos machines, nous n'avons pas utilis√© d'image Docker mais plut√¥t la commande *redis-server* dans le terminal.

Cette conception est impl√©ment√©e dans le fichier **redis_ETL.py**.

### 3Ô∏è‚É£ Multiprocessing
> Python ne permet pas de faire du parall√©lisme au niveau thread √† cause du GIL (Global Interpreter Lock) qui est une exclusion mutuelle destin√©e √† int√©grer plus facilement les librairies externes et √† ex√©cuter le code non-parall√®le plus rapidement tout en s√©curisant les threads. En effet, la gestion de la m√©moire en Python n'est pas s√ªre au niveau thread. Le GIL permet donc d'√©viter les conflits de concurrence, mais le prix √† payer reste le parall√©lisme massif au niveau thread dans ce langage.

Dans cette partie, on tente d'appliquer le multiprocessing √† notre ETL.

Cette conception est impl√©ment√©e dans le fichier **multiprocessing_ETL.py**.

## üß∂ Un ETL avec MapReduce
L'objectif est ici de combiner MapReduce et l'aspect pubsub de Redis. Ce proc√©d√© est tout d'abord appliqu√© sur [Killer Queen du groupe Queen](https://raw.githubusercontent.com/christelle101/INFO833_ETL/main/MapReduce/tst.txt?token=GHSAT0AAAAAABROFS3BDP66ZKIUA2IXSN7QYUIAFCQ) pour tester, puis sur un plus gros fichier : [les sonnets de Shakespeare](https://raw.githubusercontent.com/christelle101/INFO833_ETL/main/MapReduce/t8.shakespeare.txt?token=GHSAT0AAAAAABROFS3AYLLUP7DPBEWPJPJOYUIAF6A).

L'objectif √©tait d'√©crire un fichier JSON avec les occurrences de chaque mot. Toutefois, nous ne sommes pas encore parvenus √† r√©aliser cela √† cause d'une erreur qui doit √™tre pr√©sente dans le code. Pour le moment, nous avons le fichier **dumbp.rdb** qui a √©t√© g√©n√©r√© par Redis.